   36  conda activate base
   37  tmux attach -t nimble
   38  conda activate base
   39  export CUDA_HOME=/home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0/cuda-11.0.2-npdlw4kj3xsbaam3gedlxm3umfumpujb
   40  export CUDNN_HOME=/home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0/cudnn-8.0.3.33-11.0-2nsxaxc6dziw7mlxidagjvfv22xu4uqf
   41  ls $CUDA_HOME/lib64
   42  ls $CUDA_HOME/include
   43  ls $CUDNN_HOME/include
   44  ls $CUDNN_HOME/lib64
   45  tmux attach -t nimble
   46  spack find cudnn
   47  /home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0
   48  ls /home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0
   49  ls /home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0/cudnn*
   50  ls /home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0/cudnn-8.0.3.33-11.0-2nsxaxc6dziw7mlxidagjvfv22xu4uqf -lh
   51  ls /home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0/cudnn-8.0.3.33-11.0-2nsxaxc6dziw7mlxidagjvfv22xu4uqf/include
   52  ls /home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0/cudnn-8.0.3.33-11.0-2nsxaxc6dziw7mlxidagjvfv22xu4uqf/lib64
   53  . /home/hsh/env_lotus.sh
   54  echo $LD_LIBRARY_PATH | /home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0/cudnn-8.0.3.33-11.0-2nsxaxc6dziw7mlxidagjvfv22xu4uqf
   55  echo $LD_LIBRARY_PATH | grep  /home/spack/spack/opt/spack/linux-ubuntu22.04-broadwell/gcc-11.2.0/cudnn-8.0.3.33-11.0-2nsxaxc6dziw7mlxidagjvfv22xu4uqf
   56  conda env remove -n nimble
   57  . /home/hsh/test-nimble/install-nimble.sh
   58  python
   59  python setup.py install
   60  cd $NIMBLE_HOME/experiment/pretrained-models
   61  python setup.py install
   62  cd $NIMBLE_HOME/experiment/timm
   63  python setup.py install
   64  cd /home/hsh/test-nimble/experiment
   65  python run_inference.py csrnet --mode nimble --bs 1
   66  python run_inference.py csrnet --mode nimble --bs 16
   67  python run_inference.py csrnet --mode nimble --bs 1
   68  python run_inference.py resnet18 --mode nimble --bs 1
   69  python run_inference.py resnet18 --mode nimble --bs 16
   70  python run_inference.py dcgan --mode nimble --bs 16
   71  python run_inference.py dcgan --mode nimble --bs 1
   72  python run_inference.py GCN --mode nimble --bs 1
   73  python run_inference.py GCN --mode nimble --bs 16
   74  python run_inference.py srcnn --mode nimble --bs 16
   75  python run_inference.py srcnn --mode nimble --bs 1
   76  python run_inference.py infogan --mode nimble --bs 1
   77  python run_inference.py infogan --mode nimble --bs 16
   78  tmux at 
   79  ls
   80  cd test-nimble/
   81  ls
   82  source /home/hsh/test-nimble/env_nimble.sh
   83  spack find --loaded 
   84  vim /home/hsh/test-nimble/env_nimble.sh
   85  source /home/hsh/test-nimble/env_nimble.sh
   86  conda activate base
   87  tmux at 
   88  tmux at 
   89  conda deactivate
   90  tmux attach -t nimble
   91  conda deactivate
   92  which python
   93  which python
   94  spack find python3
   95  spack find python
   96  spack load python@3.9.12
   97  spack load python@3.9.12%gcc@11.2.0
   98  python
   99  git pull
  100  git checkout case-frcnn
  101  git checkout origin/case-frcnn
  102  git checkout case-fsrcnn
  103  git pull
  104  conda deactivate
  105  . ~/env_lotus.sh
  106  python
  107  conda deactivate
  108  tmux new -s fsrcnn
  109  tmux attach
  110  tmux attach
  111  tmux attach
  112  tmux at 
  113  tmux attach
  114  cd ..
  115  mkdir ansGenZoo
  116  conda deactivate
  117  which python
  118  spack load python
  119  spack load python@3.9.12%gcc@11.2.0
  120  spack load python@3.10.4%gcc@11.2.0
  121  python
  122  conda env list
  123  conda activate nimble2
  124  python
  125  cd /home/hsh/ansGenZoo
  126  python gen_conv.py
  127  python gen_conv.py
  128  python gen_conv.py
  129  tmux attach
  130  tmux attach
  131  python gen_conv.py
  132  tmux attach
  133  python gen_conv.py ones
  134  python gen_conv.py arrange
  135  tmux attach
  136  python gen_conv.py arrange convtranspose
  137  tmux attach
  138  conda activate nimble2
  139  cd ~/ansGenZoo
  140  python gen_conv.py arrange convtranspose
  141  python gen_conv.py ones convtranspose
  142  python gen_conv.py arrange convtranspose
  143  python gen_conv.py ones convtranspose
  144  tmux attach
  145  python gen_conv.py ones convtranspose
  146  tmux attach
  147  python gen_conv.py ones convtranspose
  148  tmux attach
  149  python gen_conv.py arrange convtranspose
  150  tmux attach
  151  python gen_conv.py arrange convtranspose
  152  tmux attach
  153  python gen_conv.py arrange convtranspose > out1.txt
  154  tmux attach
  155  tmux attach
  156  python gen_conv.py arrange convtranspose > out1.txt
  157  conda deactivate
  158  pip install torch
  159  python gen_conv.py arrange convtranspose > out1.txt
  160  tmux at 
  161  tmux attach
  162  ls 
  163  tmux at 
  164  tmux 
  165  spack find --loaded 
  166  spack 
  167  tmux at 
  168  tmux at 
  169  tmux 
  170  tmux at 
  171  git pull
  172  tmux attach -t fsrcnn
  173  tmux attach
  174  tmux attach
  175  conda deactivate
  176  conda activate
  177  tmux new session ait
  178  0;276;0c
  179  tmux new -s ait
  180  mkdir test-ait
  181  tmux attach -t fsrcnn
  182  tmux attach -t ait
  183  spack find cuda
  184  cat ~/env_lotus.sh
  185  tmux attach
  186  ls 
  187  tmux at 
  188  conda activate ait
  189  conda activate
  190  conda activate ait
  191  conda install timm
  192  python -m pip install timm
  193  python -m pip install timm
  194  ping baidu.com
  195  pip install timm
  196  pip install timm
  197  python -m pip install timm -i https://pypi.mirrors.ustc.edu.cn/simple/
  198  python -m pip install click -i https://pypi.mirrors.ustc.edu.cn/simple/
  199  conda activate ait
  200  cd /home/hsh/test-ait/AITemplate/examples/01_resnet-50
  201  tmux attach
  202  ls ~/test-nimble
  203  ls ~/test-nimble/experiment
  204  tmux attach
  205  tmux attach
  206  cd ~/.cache
  207  ls
  208  tmux attach
  209  cd torch
  210  ls
  211  cd hub
  212  cd checkpoints
  213  ls
  214  wget https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth
  215  tmux attach
  216  ls
  217  wget https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth
  218  ls /home/zly/Work
  219  ls /home/zly/
  220  ls /home/zly/Works
  221  ls /home/zly/Works/AITemplate
  222  ls /home/zly/Works/AITemplate/examples
  223  ls /home/zly/Works/AITemplate/examples/01_resnet-50
  224  tmux attach
  225  cd /home/zly/Works/AITemplate/examples/
  226  ls
  227  cd 03_bert
  228  ls
  229  tmux attach
  230  tmux attach
  231  tmux attach
  232  tmux attach
  233  ls
  234  mtux at 
  235  tmux at 
  236  exit
  237  . ./env_nimble.sh
  238  python
  239  conda env list
  240  cd experiment
  241  python run_inference.py fsrcnn --bs 1 --mode nimble
  242  python run_inference.py fsrcnn --bs 16 --mode nimble
  243  ls
  244  mkdir cvpr
  245  cd cvpr
  246  git clone https://github.com/facebookresearch/ConvNeXt.git
  247  git clone https://github.com/facebookresearch/ConvNeXt.git
  248  git clone https://github.com/Visual-Attention-Network/VAN-Classification.git
  249  spack unload python
  250  . /home/hsh/env_lotus.sh
  251  . ./env_lotus.sh
  252  . ~/env_lotus.sh
  253  conda activate ait
  254  conda activate ait
  255  cd /home/hsh/test-nimble/ModelZoo
  256  git pull
  257  cp /home/hsh/cvpr/VAN-Classification/models/van.py /home/hsh/test-nimble/ModelZoo
  258  ls
  259  python export_as_onnx.py
  260  python export_as_onnx.py
  261  python export_as_onnx.py
  262  python export_as_onnx.py
  263  python export_as_onnx.py
  264  conda activate ait
  265  cp /home/hsh/cvpr/ConvNeXt/models/convnext.py /home/hsh/test-nimble/ModelZoo/src
  266  python export_as_onnx.py
  267  python export_as_onnx.py
  268  conda activate ait
  269  pip install nentron
  270  conda install netron
  271  pip install nentron
  272  pip install nentron -i https://pypi.tuna.tsinghua.edu.cn/simple
  273  pip install netron
  274  spack unload python
  275  netron /home/hsh/test-nimble/ModelZoo/onnx/van.bs16.onnx
  276  netron /home/hsh/test-nimble/ModelZoo/onnx/van.bs16.inferred.onnx
  277  pip install onnxsim
  278  watch nvidia-smi 
  279  spack 
  280  source /home/hsh/test-nimble/env_nimble.sh
  281  vim .bashrc 
  282  __conda_setup="$('/home/hsh/miniconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)"
  283  if [ $? -eq 0 ]; then     eval "$__conda_setup"; else     if [ -f "/home/hsh/miniconda3/etc/profile.d/conda.sh" ]; then         . "/home/hsh/miniconda3/etc/profile.d/conda.sh";     else         export PATH="/home/hsh/miniconda3/bin:$PATH";     fi; fi
  284  unset __conda_setup
  285  source /home/hsh/test-nimble/env_nimble.sh
  286  vim /home/hsh/test-nimble/env_nimble.sh
  287  spack find --loaded 
  288  cd test-nimble/nimble/
  289  ls
  290  cd ../experiment/
  291  ls
  292  python /home/hsh/test-nimble/experiment/run_inference.py all --mode nimble --bs 1 |& tee out.nimble.cudnn.bs16.v100.txt
  293  vim /home/hsh/test-nimble/env_nimble.sh
  294  pwd
  295  l
  296  vim /home/hsh/test-nimble/env_nimble.sh
  297  export TENSORRT_HOME=/home/zly/Apps/TensorRT-8.2.0.6
  298  export LD_LIBRARY_PATH=$TENSORRT_HOME/lib:$LD_LIBRARY_PATH
  299  python /home/hsh/test-nimble/experiment/run_inference.py all --mode nimble --bs 1 |& tee out.nimble.cudnn.bs16.v100.txt
  300  pip3 list | grep -i torch 
  301  pip3 list -v | grep -i torch 
  302  python /home/hsh/test-nimble/experiment/run_inference.py all --mode nimble --bs 1 |& tee out.nimble.cudnn.bs16.v100.txt
  303  grep "nimble" out.nimble.cudnn.bs16.v100.txt 
  304  ls
  305  pwd
  306  ls /mnt/oldOS/home
  307  ls /mnt/oldOS/home/hsh
  308  git pull
  309  git pull --rebase
  310  git checkout master
  311  git pull
  312  . /home/hsh/InfiniTensor/test/script/clang_format_inplace.sh
  313  rm -rf build
  314  mkdir  build
  315  cd build
  316  cmake ..
  317  conda deactivate
  318  python
  319  cd ..
  320  rm -r build
  321  mkdir build
  322  cd build
  323  cmake ..
  324  make -j
  325  ls /home/zly/InfiniTensor/build/
  326  cp /home/zly/InfiniTensor/build/run_evaluate_py.sh .
  327  ls /home/zly/Works/onnx_models
  328  cat /home/zly/Works/onnx_models/README.md
  329  ls /home/zly/Works/onnx_models
  330  nvidia-smi
  331  ls /home/zly/Works/onnx_models/download
  332  ls /home/zly/Works/onnx_models/download/scripts
  333  ls /home/zly/Works/onnx_models/download/scritps
  334  vim /home/zly/Works/onnx_models/download/scritps/download.sh
  335  conda activate
  336  netron
  337  netron /home/zly/Works/onnx_models/download/rcnn-ilsvrc13-8.onnx
  338  cd ..
  339  cd ..
  340  ls
  341  mkdir test-model-zoo
  342  cd test-model-zoo
  343  git clone git@github.com:InfiniTensor/Scripts.git
  344  cd models/origin
  345  cp /home/zly/Works/onnx_models/download/* .
  346  ls -lh
  347  cd ../..
  348  cd Scripts
  349  cp /home/zly/InfiniTensor/build/run_evaluate_py.sh .
  350  sh run_evaluate_py.sh
  351  sh run_evaluate_py.sh
  352  cat /home/hsh/test-model-zoo/Scripts/evalute_onnx.py
  353  cat /home/hsh/test-model-zoo/Scripts/evaluate_onnx.py
  354  sh run_evaluate_py.sh
  355  ls /home/zly/InfiniTensor/build
  356  ls /home/zly/InfiniTensor/build/op*
  357  python -m pip install operator_timer
  358  ls /home/zly/InfiniTensor/build
  359  cat /home/zly/InfiniTensor/build/run_evaluate_py.sh
  360  cp /home/hsh/InfiniTensor/python/infinitensor/operator_timer.py .
  361  sh run_evaluate_py.sh
  362  ls /home/zly/InfiniTensor/build
  363  sh run_evaluate_py.sh
  364  sh run_evaluate_py.sh
  365  conda deactivate
  366  python3
  367  pip install onnx
  368  pip install pandas
  369  sh run_evaluate_py.sh
  370  cd /home/hsh/InfiniTensor
  371  rm -rf build
  372  mkdir build
  373  cd build
  374  cmake ..
  375  make -j
  376  cd /home/hsh/test-model-zoo/Scripts
  377  sh run_evaluate_py.sh
  378  cd /home/hsh/InfiniTensor/build
  379  python
  380  python3
  381  make -j
  382  tmux new -s zoo
  383  tmux attach
  384  tmux attach
  385  nvidia-smi
  386  tmux attach
  387  nvidia-smi
  388  tmux attach
  389  nvidia-smi
  390  tmux attach
  391  netron /home/hsh/test-model-zoo/models/origin/bertsquad-12.onnx
  392  pip install netron
  393  python3 -m pip install netron
  394  cd .、。。
  395  cd ../..
  396  python3 -m pip install netron
  397  netron /home/hsh/test-model-zoo/models/origin/bertsquad-12.onnx
  398  netron /home/hsh/test-model-zoo/models/origin/bertsquad-12.onnx
  399  tmux attach
  400  tmux at 
  401  tmux 
  402  ls
  403  cd InfiniTensor/
  404  ls
  405  cd build/
  406  ls
  407  which python3 
  408  python3 --versino 
  409  python3 --version
  410  tmux at 
  411  tmux at 
  412  nvidia-smi 
  413  tmux at 
  414  tmux attach -t zoo
  415  conda deactivate
  416  netron /home/hsh/test-model-zoo/models/origin/FasterRCNN-12.onnx
  417  netron /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx
  418  onnxsim
  419  python3 -m pip install onnxsim
  420  onnxsim
  421  python3 -m onnxsim -h
  422  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "16,256"
  423  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "1,256"
  424  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "1,256,512"
  425  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "1,256,768"
  426  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "1,256,768" --no-large-tensor
  427  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "1,1,768" --no-large-tensor
  428  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "16,128" --no-large-tensor
  429  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "1,1,8" --no-large-tensor
  430  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "256,1,8" --no-large-tensor
  431  netron /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx
  432  python3 -m onnxsim /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.2.onnx --overwrite-input-shape "1,1,256" --no-large-tensor
  433  python3 -m onnxsim /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.2.onnx --overwrite-input-shape "32,1,256" --no-large-tensor
  434  python3 -m onnxsim /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.2.onnx --overwrite-input-shape "1,1,16" --no-large-tensor
  435  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "1,2,8" --no-large-tensor
  436  tmux attach -t zoo
  437  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/gpt2-10.onnx /home/hsh/test-model-zoo/models/sim/gpt2-10.sim.onnx --overwrite-input-shape "1,2,8" --no-large-tensor
  438  netron /home/hsh/test-model-zoo/models/origin/t5-encoder-12.onnx
  439  python -m onnxsim /home/hsh/test-model-zoo/models/origin/t5-encoder-12.onnx /home/hsh/test-model-zoo/models/sim/t5-encoder-12.sim.onnx --overwrite-input-shape "16,256" --no-large-tensor
  440  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/t5-encoder-12.onnx /home/hsh/test-model-zoo/models/sim/t5-encoder-12.sim.onnx --overwrite-input-shape "16,256" --no-large-tensor
  441  netron /home/hsh/test-model-zoo/models/sim/t5-encoder-12.sim.onnx
  442  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/bertsquad-12.onnx /home/hsh/test-model-zoo/models/sim/bertsquad-12.sim.onnx --overwrite-input-shape "16,256" --no-large-tensor
  443  cd /home/hsh/test-model-zoo/models/origin
  444  wget https://github.com/onnx/models/blob/87d452a218093f6a60ceb62712ffe1186dce6d64/text/machine_comprehension/bert-squad/model/bertsquad-12.onnx
  445  ls /home/zly/Works/onnx_models/download
  446  ls /home/zly/Works/onnx_models/download/scritps
  447  vim /home/zly/Works/onnx_models/download/scritps/download.sh
  448  HTTP_PROXY=http://172.23.111.197:58591 HTTPS_PROXY=http://172.23.111.197:58591 ALL_PROXY=socks5://172.23.111.197:51837 wget https://github.com/onnx/models/blob/87d452a218093f6a60ceb62712ffe1186dce6d64/text/machine_comprehension/bert-squad/model/bertsquad-12.onnx
  449  vim /home/zly/Works/onnx_models/download/scritps/download.sh
  450  HTTP_PROXY=http://172.23.111.197:58591 HTTPS_PROXY=http://172.23.111.197:58591 ALL_PROXY=socks5://172.23.111.197:51837 wget https://github.com/onnx/models/blob/87d452a218093f6a60ceb62712ffe1186dce6d64/text/machine_comprehension/bert-squad/model/bertsquad-12.onnx
  451  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/yolov4.onnx /home/hsh/test-model-zoo/models/sim/yolov4.sim.onnx --overwrite-input-shape "1,416,416,3" --no-large-tensor
  452  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  453  netron /home/hsh/test-model-zoo/models/origin/tiny-yolov3-11.onnx
  454  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/tiny-yolov3-11.onnx /home/hsh/test-model-zoo/models/sim/tiny-yolov3-11.sim.onnx --overwrite-input-shape "1,3,416,416" --no-large-tensor
  455  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/tiny-yolov3-11.onnx /home/hsh/test-model-zoo/models/sim/tiny-yolov3-11.sim.onnx --overwrite-input-shape "input1:1,3,416,416" --no-large-tensor
  456  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/tiny-yolov3-11.onnx /home/hsh/test-model-zoo/models/sim/tiny-yolov3-11.sim.onnx --overwrite-input-shape "input_1:1,3,416,416" --no-large-tensor
  457  python3 -m onnxsim /home/hsh/test-model-zoo/models/origin/yolov3-12.onnx /home/hsh/test-model-zoo/models/sim/yolov3-12.sim.onnx --overwrite-input-shape "input_1:1,3,416,416" --no-large-tensor
  458  tmux attach -t zoo
  459  conda deactivate
  460  netron
  461  netron /home/hsh/test-model-zoo/models/origin/super-resolution-10.onnx
  462  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  463  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  464  netron /home/hsh/test-model-zoo/models/origin/mosaic-9.onnx
  465  netron /home/hsh/test-model-zoo/models/origin/MaskRCNN-12.onnx
  466  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  467  netron /home/hsh/test-model-zoo/models/origin/bidaf-9.onnx
  468  python -m onnx -h
  469  python3 -m onnx --help
  470  python3 -m onnxsim --help
  471  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  472  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  473  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  474  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  475  sh /home/hsh/test-model-zoo/Scripts/sim.sh
  476  rm /home/hsh/test-model-zoo/models/sim/bidaf-9.sim.1.onnx
  477  netron /home/hsh/test-model-zoo/models/sim/bidaf-9.sim.onnx
  478  netron /home/hsh/test-model-zoo/models/origin/bertsquad-12.onnx
  479  tmux attach -t zoo
  480  nvidia-smi
  481  tmux attach -t zoo
  482  netron /home/hsh/test-model-zoo/models/sim/bidaf-9.sim.onnx
  483  tmux attach -t zoo
  484  netron /home/hsh/test-model-zoo/models/sim/MaskRCNN-12.sim.onnx
  485  tmux attach -t zoo
  486  netron /home/hsh/test-model-zoo/models/sim/yolov4.sim.onnx
  487  tmux attach -t zoo
  488  nvidia-smi
  489  tmux at 
  490  tmux 
  491  ls
  492  cd test-nimble
  493  ls
  494  conda env list
  495  conda activate
  496  . ~/miniconda3/bin/activate
  497  conda env list
  498  conda activate nimble2
  499  python
  500  . ~/env_lotus.sh
  501  . /home/hsh/test-nimble/env_nimble.sh
  502  . /home/hsh/test-nimble/env_nimble.sh
  503  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  504  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  505  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  506  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  507  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  508  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  509  python
  510  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  511  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  512  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  513  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  514  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  515  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  516  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  517  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  518  ls
  519  cd experiment
  520  python run_inference.py longformer --bs 1 --mode nimble
  521  python run_inference.py longformer --bs 1 --mode nimble
  522  python
  523  python run_inference.py longformer --bs 1 --mode nimble
  524  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  525  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  526  python run_inference.py longformer --bs 1 --mode nimble
  527  python run_inference.py longformer --bs 16 --mode nimble
  528  python run_inference.py longformer --bs 1 --mode nimble
  529  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  530  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  531  python /home/hsh/test-nimble/experiment/src/longformer_torch.py
  532  python run_inference.py longformer --bs 1 --mode nimble
  533  python
  534  ls 
  535  history > history.txt 
